{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import time\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "class ERA5Retriever:\n",
    "    def __init__(self, output_dir='era5_data'):\n",
    "        \"\"\"初始化ERA5数据获取器\"\"\"\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.client = cdsapi.Client()\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # 定义中欧研究区域 [North, West, South, East]\n",
    "        # 覆盖德国、法国东部、波兰等中欧核心区域\n",
    "        self.study_area = [55, 5, 45, 20]\n",
    "        \n",
    "        # 定义关键预报变量\n",
    "        self.variables = {\n",
    "            # 基本预报变量\n",
    "            \"2m_temperature\": \"基本温度场\",\n",
    "            \"total_precipitation\": \"降水\",\n",
    "            \"mean_sea_level_pressure\": \"海平面气压\",\n",
    "            \n",
    "            # 环流特征变量\n",
    "            \"10m_u_component_of_wind\": \"纬向风\",\n",
    "            \"10m_v_component_of_wind\": \"经向风\",\n",
    "            \"geopotential_at_500hpa\": \"500hPa位势高度\",\n",
    "            \n",
    "            # 热力和水汽特征\n",
    "            \"relative_humidity_at_850hpa\": \"850hPa相对湿度\",\n",
    "            \"total_column_water_vapour\": \"整层水汽含量\",\n",
    "            \n",
    "            # 边界层特征\n",
    "            \"boundary_layer_height\": \"边界层高度\",\n",
    "            \"surface_pressure\": \"地面气压\",\n",
    "        }\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"设置日志记录\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.output_dir / 'era5_retrieval.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger('ERA5Retriever')\n",
    "\n",
    "    def retrieve_data(self, year, month, output_file=None):\n",
    "        \"\"\"获取ERA5数据\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        year : int\n",
    "            年份\n",
    "        month : int\n",
    "            月份\n",
    "        output_file : str, optional\n",
    "            输出文件名\n",
    "        \"\"\"\n",
    "        if output_file is None:\n",
    "            output_file = self.output_dir / f'era5_{year}_{month:02d}.nc'\n",
    "            \n",
    "        if output_file.exists():\n",
    "            self.logger.info(f\"File {output_file} already exists, skipping...\")\n",
    "            return output_file\n",
    "\n",
    "        try:\n",
    "            # 构建请求参数\n",
    "            request = {\n",
    "                \"format\": \"netcdf\",\n",
    "                \"product_type\": \"reanalysis\",\n",
    "                \"variable\": list(self.variables.keys()),\n",
    "                \"year\": str(year),\n",
    "                \"month\": f\"{month:02d}\",\n",
    "                \"day\": [f\"{day:02d}\" for day in range(1, 32)],\n",
    "                \"time\": [f\"{hour:02d}:00\" for hour in range(0, 24, 6)],  # 6小时间隔\n",
    "                \"area\": self.study_area,\n",
    "                \"pressure_level\": [\"500\", \"850\"],  # 添加重要气压层\n",
    "            }\n",
    "\n",
    "            # 获取数据\n",
    "            self.logger.info(f\"Retrieving data for {year}-{month:02d}\")\n",
    "            self.client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                request,\n",
    "                output_file\n",
    "            )\n",
    "            \n",
    "            # 验证下载的数据\n",
    "            self._validate_data(output_file)\n",
    "            \n",
    "            self.logger.info(f\"Successfully downloaded and validated {output_file}\")\n",
    "            time.sleep(5)  # 避免请求过于频繁\n",
    "            \n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error retrieving data for {year}-{month:02d}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _validate_data(self, file_path):\n",
    "        \"\"\"验证下载的数据完整性和质量\"\"\"\n",
    "        try:\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            \n",
    "            # 检查变量是否完整\n",
    "            missing_vars = set(self.variables.keys()) - set(ds.data_vars)\n",
    "            if missing_vars:\n",
    "                self.logger.warning(f\"Missing variables in {file_path}: {missing_vars}\")\n",
    "            \n",
    "            # 检查缺失值\n",
    "            for var in ds.data_vars:\n",
    "                missing_ratio = ds[var].isnull().mean().values\n",
    "                if missing_ratio > 0:\n",
    "                    self.logger.warning(f\"Variable {var} has {missing_ratio*100:.2f}% missing values\")\n",
    "            \n",
    "            ds.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error validating {file_path}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：获取10年的ERA5数据\"\"\"\n",
    "    retriever = ERA5Retriever()\n",
    "    \n",
    "    # 定义时间范围：2012-2021年的数据\n",
    "    years = range(2012, 2022)\n",
    "    # 冬季月份 (包括上一年11-12月和当年1-3月)\n",
    "    months = [11, 12, 1, 2, 3]\n",
    "    \n",
    "    # 获取数据\n",
    "    total_files = len(years) * len(months)\n",
    "    completed_files = 0\n",
    "    \n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            # 处理跨年的情况\n",
    "            if month in [1, 2, 3]:\n",
    "                if year == years[-1]:  \n",
    "                    continue  # 跳过最后一年的1-3月\n",
    "                current_year = year\n",
    "            else:\n",
    "                current_year = year - 1  # 11-12月属于上一年的冬季\n",
    "            \n",
    "            try:\n",
    "                retriever.retrieve_data(current_year, month)\n",
    "                completed_files += 1\n",
    "                print(f\"Progress: {completed_files}/{total_files} files completed\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to retrieve data for {current_year}-{month}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(\"Data retrieval completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimateAnalyzer:\n",
    "    def __init__(self, data_dir='era5_data', output_dir='analysis_results'):\n",
    "        \"\"\"初始化气候分析器\"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.setup_logging()\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"设置日志记录\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.output_dir / 'climate_analysis.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger('ClimateAnalyzer')\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载ERA5数据并进行初步处理\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Loading ERA5 data...\")\n",
    "            data_files = sorted(self.data_dir.glob('era5_*.nc'))\n",
    "            ds = xr.open_mfdataset(data_files, combine='by_coords')\n",
    "            \n",
    "            # 基本信息记录\n",
    "            self.logger.info(f\"Data loaded: {len(data_files)} files\")\n",
    "            self.logger.info(f\"Time range: {ds.valid_time.min().values} to {ds.valid_time.max().values}\")\n",
    "            return ds\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def calculate_basic_statistics(self, ds):\n",
    "        \"\"\"计算基本统计量\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Calculating basic statistics...\")\n",
    "            stats = {}\n",
    "            \n",
    "            # 1. 时间维度统计\n",
    "            stats['temporal'] = {\n",
    "                'total_days': len(ds.valid_time),\n",
    "                'years_covered': len(np.unique(ds.valid_time.dt.year)),\n",
    "                'seasons_covered': len(np.unique(ds.valid_time.dt.season))\n",
    "            }\n",
    "            \n",
    "            # 2. 变量基本统计\n",
    "            stats['variables'] = {}\n",
    "            for var in ds.data_vars:\n",
    "                var_stats = {\n",
    "                    'mean': float(ds[var].mean()),\n",
    "                    'std': float(ds[var].std()),\n",
    "                    'min': float(ds[var].min()),\n",
    "                    'max': float(ds[var].max()),\n",
    "                    'missing_ratio': float(ds[var].isnull().mean()),\n",
    "                    'spatial_variability': float(ds[var].std(dim=['latitude', 'longitude']).mean())\n",
    "                }\n",
    "                stats['variables'][var] = var_stats\n",
    "            \n",
    "            # 3. 区域平均特征\n",
    "            stats['regional'] = self.calculate_regional_statistics(ds)\n",
    "            \n",
    "            # 4. 季节性特征\n",
    "            stats['seasonal'] = self.calculate_seasonal_statistics(ds)\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating statistics: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def calculate_regional_statistics(self, ds):\n",
    "        \"\"\"计算区域统计特征\"\"\"\n",
    "        regions = {\n",
    "            'north': {'lat': slice(50, 55), 'lon': slice(5, 20)},\n",
    "            'central': {'lat': slice(45, 50), 'lon': slice(5, 20)},\n",
    "            'south': {'lat': slice(40, 45), 'lon': slice(5, 20)}\n",
    "        }\n",
    "        \n",
    "        regional_stats = {}\n",
    "        for region_name, coords in regions.items():\n",
    "            region_ds = ds.sel(**coords)\n",
    "            stats = {}\n",
    "            for var in ds.data_vars:\n",
    "                stats[var] = {\n",
    "                    'mean': float(region_ds[var].mean()),\n",
    "                    'std': float(region_ds[var].std()),\n",
    "                    'extremes': {\n",
    "                        'p95': float(region_ds[var].quantile(0.95)),\n",
    "                        'p05': float(region_ds[var].quantile(0.05))\n",
    "                    }\n",
    "                }\n",
    "            regional_stats[region_name] = stats\n",
    "            \n",
    "        return regional_stats\n",
    "\n",
    "    def calculate_seasonal_statistics(self, ds):\n",
    "        \"\"\"计算季节性统计特征\"\"\"\n",
    "        # 按季节分组\n",
    "        seasonal_ds = ds.groupby('valid_time.season')\n",
    "        \n",
    "        seasonal_stats = {}\n",
    "        for season, season_ds in seasonal_ds:\n",
    "            stats = {}\n",
    "            for var in ds.data_vars:\n",
    "                stats[var] = {\n",
    "                    'mean': float(season_ds[var].mean()),\n",
    "                    'std': float(season_ds[var].std()),\n",
    "                    'variability': float(season_ds[var].std(dim=['latitude', 'longitude']).mean())\n",
    "                }\n",
    "            seasonal_stats[season] = stats\n",
    "            \n",
    "        return seasonal_stats\n",
    "\n",
    "    def generate_summary_report(self, stats):\n",
    "        \"\"\"生成统计分析报告\"\"\"\n",
    "        report_path = self.output_dir / 'statistical_analysis_report.txt'\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"ERA5 Data Statistical Analysis Report\\n\")\n",
    "            f.write(\"===================================\\n\\n\")\n",
    "            \n",
    "            # 1. 数据概览\n",
    "            f.write(\"1. Data Overview\\n\")\n",
    "            f.write(\"--------------\\n\")\n",
    "            f.write(f\"Total days analyzed: {stats['temporal']['total_days']}\\n\")\n",
    "            f.write(f\"Years covered: {stats['temporal']['years_covered']}\\n\")\n",
    "            f.write(f\"Seasons covered: {stats['temporal']['seasons_covered']}\\n\\n\")\n",
    "            \n",
    "            # 2. 变量统计\n",
    "            f.write(\"2. Variable Statistics\\n\")\n",
    "            f.write(\"-------------------\\n\")\n",
    "            for var, var_stats in stats['variables'].items():\n",
    "                f.write(f\"\\n{var}:\\n\")\n",
    "                for stat, value in var_stats.items():\n",
    "                    f.write(f\"  {stat}: {value:.4f}\\n\")\n",
    "            \n",
    "            # 3. 区域特征\n",
    "            f.write(\"\\n3. Regional Characteristics\\n\")\n",
    "            f.write(\"-------------------------\\n\")\n",
    "            for region, region_stats in stats['regional'].items():\n",
    "                f.write(f\"\\n{region.upper()}:\\n\")\n",
    "                for var, var_stats in region_stats.items():\n",
    "                    f.write(f\"  {var}:\\n\")\n",
    "                    for stat, value in var_stats.items():\n",
    "                        if isinstance(value, dict):\n",
    "                            f.write(f\"    {stat}:\\n\")\n",
    "                            for sub_stat, sub_value in value.items():\n",
    "                                f.write(f\"      {sub_stat}: {sub_value:.4f}\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"    {stat}: {value:.4f}\\n\")\n",
    "            \n",
    "            # 4. 季节特征\n",
    "            f.write(\"\\n4. Seasonal Patterns\\n\")\n",
    "            f.write(\"------------------\\n\")\n",
    "            for season, season_stats in stats['seasonal'].items():\n",
    "                f.write(f\"\\n{season}:\\n\")\n",
    "                for var, var_stats in season_stats.items():\n",
    "                    f.write(f\"  {var}:\\n\")\n",
    "                    for stat, value in var_stats.items():\n",
    "                        f.write(f\"    {stat}: {value:.4f}\\n\")\n",
    "        \n",
    "        self.logger.info(f\"Statistical analysis report generated: {report_path}\")\n",
    "        return report_path\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    try:\n",
    "        # 初始化分析器\n",
    "        analyzer = ClimateAnalyzer()\n",
    "        \n",
    "        # 加载数据\n",
    "        ds = analyzer.load_data()\n",
    "        \n",
    "        # 计算基本统计量\n",
    "        stats = analyzer.calculate_basic_statistics(ds)\n",
    "        \n",
    "        # 生成报告\n",
    "        report_path = analyzer.generate_summary_report(stats)\n",
    "        \n",
    "        print(f\"Analysis completed. Report saved to: {report_path}\")\n",
    "        return ds, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds, stats = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pathlib import Path\n",
    "\n",
    "class ClimateVisualizer:\n",
    "    def __init__(self, data_dir='era5_data', output_dir='visualization_results'):\n",
    "        \"\"\"初始化气候数据可视化器\"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # 设置绘图风格\n",
    "        plt.style.use('default')\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        plt.rcParams['font.family'] = 'Times New Roman'\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        \n",
    "    def create_spatial_temporal_analysis(self, ds):\n",
    "        \"\"\"创建时空分析综合图\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 12))\n",
    "        gs = GridSpec(2, 2, figure=fig)\n",
    "        \n",
    "        # 1. 空间平均场\n",
    "        ax1 = fig.add_subplot(gs[0, :], projection=ccrs.PlateCarree())\n",
    "        self._plot_mean_field(ds, ax1)\n",
    "        \n",
    "        # 2. 时间序列分析\n",
    "        ax2 = fig.add_subplot(gs[1, 0])\n",
    "        self._plot_time_series(ds, ax2)\n",
    "        \n",
    "        # 3. 季节循环\n",
    "        ax3 = fig.add_subplot(gs[1, 1])\n",
    "        self._plot_seasonal_cycle(ds, ax3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def _plot_mean_field(self, ds, ax):\n",
    "        \"\"\"绘制平均场分布\"\"\"\n",
    "        mean_temp = ds['t2m'].mean(dim='valid_time')\n",
    "        mean_temp.plot(\n",
    "            ax=ax,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap='RdBu_r',\n",
    "            robust=True\n",
    "        )\n",
    "        ax.coastlines()\n",
    "        ax.gridlines()\n",
    "        ax.set_title('Mean Temperature Distribution')\n",
    "        return ax\n",
    "        \n",
    "    def _plot_time_series(self, ds, ax):\n",
    "        \"\"\"绘制时间序列\"\"\"\n",
    "        time_series = ds['t2m'].mean(dim=['latitude', 'longitude'])\n",
    "        time_series.plot(ax=ax)\n",
    "        ax.set_title('Temperature Time Series')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Temperature (K)')\n",
    "        return ax\n",
    "        \n",
    "    def _plot_seasonal_cycle(self, ds, ax):\n",
    "        \"\"\"绘制季节循环\"\"\"\n",
    "        monthly_means = ds['t2m'].groupby('valid_time.month').mean()\n",
    "        monthly_means.mean(dim=['latitude', 'longitude']).plot(ax=ax, marker='o')\n",
    "        ax.set_title('Seasonal Cycle')\n",
    "        ax.set_xlabel('Month')\n",
    "        ax.set_ylabel('Temperature (K)')\n",
    "        return ax\n",
    "\n",
    "    def create_climate_patterns_plot(self, ds):\n",
    "        \"\"\"创建气候模态分析图\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        gs = GridSpec(3, 1, figure=fig)\n",
    "        \n",
    "        # 1. 温度-压力关系\n",
    "        ax1 = fig.add_subplot(gs[0])\n",
    "        self._plot_temp_pressure_relationship(ds, ax1)\n",
    "        \n",
    "        # 2. 区域平均对比\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        self._plot_regional_comparison(ds, ax2)\n",
    "        \n",
    "        # 3. 季节变化趋势\n",
    "        ax3 = fig.add_subplot(gs[2])\n",
    "        self._plot_seasonal_trends(ds, ax3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def _plot_temp_pressure_relationship(self, ds, ax):\n",
    "        \"\"\"绘制温度与气压的关系\"\"\"\n",
    "        temp = ds['t2m'].mean(dim=['latitude', 'longitude'])\n",
    "        pressure = ds['msl'].mean(dim=['latitude', 'longitude'])\n",
    "        ax.scatter(temp, pressure, alpha=0.5)\n",
    "        ax.set_title('Temperature-Pressure Relationship')\n",
    "        ax.set_xlabel('Temperature (K)')\n",
    "        ax.set_ylabel('Mean Sea Level Pressure (hPa)')\n",
    "        return ax\n",
    "        \n",
    "    def _plot_regional_comparison(self, ds, ax):\n",
    "        \"\"\"绘制区域对比\"\"\"\n",
    "        regions = {\n",
    "            'North': {'lat': slice(50, 55), 'lon': slice(5, 20)},\n",
    "            'Central': {'lat': slice(45, 50), 'lon': slice(5, 20)},\n",
    "            'South': {'lat': slice(40, 45), 'lon': slice(5, 20)}\n",
    "        }\n",
    "        \n",
    "        for region_name, coords in regions.items():\n",
    "            temp = ds['t2m'].sel(**coords).mean(dim=['latitude', 'longitude'])\n",
    "            temp.plot(ax=ax, label=region_name)\n",
    "            \n",
    "        ax.set_title('Regional Temperature Comparison')\n",
    "        ax.legend()\n",
    "        return ax\n",
    "        \n",
    "    def _plot_seasonal_trends(self, ds, ax):\n",
    "        \"\"\"绘制季节变化趋势\"\"\"\n",
    "        seasonal = ds['t2m'].groupby('valid_time.season').mean()\n",
    "        seasonal.mean(dim=['latitude', 'longitude']).plot(ax=ax)\n",
    "        ax.set_title('Seasonal Temperature Trends')\n",
    "        return ax\n",
    "\n",
    "    def create_extreme_events_analysis(self, ds):\n",
    "        \"\"\"创建极端事件分析图\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        gs = GridSpec(2, 2, figure=fig)\n",
    "        \n",
    "        # 1. 温度分布\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        self._plot_temperature_distribution(ds, ax1)\n",
    "        \n",
    "        # 2. 极端事件空间分布\n",
    "        ax2 = fig.add_subplot(gs[0, 1], projection=ccrs.PlateCarree())\n",
    "        self._plot_extreme_events_spatial(ds, ax2)\n",
    "        \n",
    "        # 3. 极端事件时间演变\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        self._plot_extreme_events_temporal(ds, ax3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def _plot_temperature_distribution(self, ds, ax):\n",
    "        \"\"\"绘制温度分布\"\"\"\n",
    "        temp = ds['t2m'].values.flatten()\n",
    "        sns.histplot(temp, bins=50, ax=ax)\n",
    "        ax.set_title('Temperature Distribution')\n",
    "        ax.set_xlabel('Temperature (K)')\n",
    "        return ax\n",
    "        \n",
    "    def _plot_extreme_events_spatial(self, ds, ax):\n",
    "        \"\"\"绘制极端事件空间分布\"\"\"\n",
    "        extreme_temp = ds['t2m'].quantile(0.95, dim='valid_time')\n",
    "        extreme_temp.plot(\n",
    "            ax=ax,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap='RdBu_r',\n",
    "            robust=True\n",
    "        )\n",
    "        ax.coastlines()\n",
    "        ax.set_title('95th Percentile Temperature')\n",
    "        return ax\n",
    "        \n",
    "    def _plot_extreme_events_temporal(self, ds, ax):\n",
    "        \"\"\"绘制极端事件时间演变\"\"\"\n",
    "        temp = ds['t2m'].mean(dim=['latitude', 'longitude'])\n",
    "        q95 = temp.quantile(0.95)\n",
    "        extreme_days = (temp > q95).astype(int)\n",
    "        extreme_days.plot(ax=ax)\n",
    "        ax.set_title('Extreme Temperature Days')\n",
    "        return ax\n",
    "\n",
    "    def generate_all_plots(self, ds):\n",
    "        \"\"\"生成所有图表并保存\"\"\"\n",
    "        try:\n",
    "            # 1. 时空分析\n",
    "            spatial_temporal_fig = self.create_spatial_temporal_analysis(ds)\n",
    "            spatial_temporal_fig.savefig(\n",
    "                self.output_dir / 'spatial_temporal_analysis.png', \n",
    "                dpi=300, \n",
    "                bbox_inches='tight'\n",
    "            )\n",
    "            plt.close(spatial_temporal_fig)\n",
    "            \n",
    "            # 2. 气候模态\n",
    "            patterns_fig = self.create_climate_patterns_plot(ds)\n",
    "            patterns_fig.savefig(\n",
    "                self.output_dir / 'climate_patterns.png', \n",
    "                dpi=300, \n",
    "                bbox_inches='tight'\n",
    "            )\n",
    "            plt.close(patterns_fig)\n",
    "            \n",
    "            # 3. 极端事件分析\n",
    "            extremes_fig = self.create_extreme_events_analysis(ds)\n",
    "            extremes_fig.savefig(\n",
    "                self.output_dir / 'extreme_events.png', \n",
    "                dpi=300, \n",
    "                bbox_inches='tight'\n",
    "            )\n",
    "            plt.close(extremes_fig)\n",
    "            \n",
    "            print(f\"\\nAll figures have been generated and saved in: {self.output_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating plots: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 加载数据\n",
    "        data_dir = Path('era5_data')\n",
    "        ds = xr.open_mfdataset(str(data_dir / 'era5_*.nc'), combine='by_coords')\n",
    "        \n",
    "        # 初始化可视化器\n",
    "        visualizer = ClimateVisualizer()\n",
    "        \n",
    "        # 生成所有图表\n",
    "        visualizer.generate_all_plots(ds)\n",
    "        \n",
    "        return ds\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from eofs.xarray import Eof\n",
    "\n",
    "class ClimateDiagnostics:\n",
    "    def __init__(self, data_dir='era5_data', output_dir='analysis_results'):\n",
    "        \"\"\"初始化气候诊断分析器\"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"设置日志记录\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.output_dir / 'climate_diagnostics.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger('ClimateDiagnostics')\n",
    "\n",
    "    def basic_statistics(self, ds):\n",
    "        \"\"\"计算基本统计量\"\"\"\n",
    "        self.logger.info(\"Computing basic statistics...\")\n",
    "        stats = {}\n",
    "        \n",
    "        try:\n",
    "            for var in ds.data_vars:\n",
    "                # 时间平均\n",
    "                temporal_mean = ds[var].mean(dim='valid_time')\n",
    "                temporal_std = ds[var].std(dim='valid_time')\n",
    "                \n",
    "                # 空间平均\n",
    "                spatial_mean = ds[var].mean(dim=['latitude', 'longitude'])\n",
    "                spatial_std = ds[var].std(dim=['latitude', 'longitude'])\n",
    "                \n",
    "                # 季节性\n",
    "                seasonal = ds[var].groupby('valid_time.season').mean()\n",
    "                \n",
    "                # 极值分析\n",
    "                extremes = {\n",
    "                    'max': float(ds[var].max()),\n",
    "                    'min': float(ds[var].min()),\n",
    "                    'p95': float(ds[var].quantile(0.95)),\n",
    "                    'p05': float(ds[var].quantile(0.05))\n",
    "                }\n",
    "                \n",
    "                stats[var] = {\n",
    "                    'temporal_statistics': {\n",
    "                        'mean': temporal_mean,\n",
    "                        'std': temporal_std\n",
    "                    },\n",
    "                    'spatial_statistics': {\n",
    "                        'mean': spatial_mean,\n",
    "                        'std': spatial_std\n",
    "                    },\n",
    "                    'seasonal_means': seasonal,\n",
    "                    'extremes': extremes\n",
    "                }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in basic statistics: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def circulation_analysis(self, ds):\n",
    "        \"\"\"分析大气环流特征\"\"\"\n",
    "        self.logger.info(\"Analyzing circulation patterns...\")\n",
    "        circulation = {}\n",
    "        \n",
    "        try:\n",
    "            # 计算位势高度梯度\n",
    "            if 'z' in ds:\n",
    "                circulation['gph_gradient'] = ds['z'].differentiate('latitude')\n",
    "                \n",
    "            # 计算风场辐散\n",
    "            if all(var in ds for var in ['u10', 'v10']):\n",
    "                u_diff = ds['u10'].differentiate('longitude')\n",
    "                v_diff = ds['v10'].differentiate('latitude')\n",
    "                circulation['divergence'] = u_diff + v_diff\n",
    "            \n",
    "            # 计算涡度\n",
    "            if all(var in ds for var in ['u10', 'v10']):\n",
    "                u_y = ds['u10'].differentiate('latitude')\n",
    "                v_x = ds['v10'].differentiate('longitude')\n",
    "                circulation['vorticity'] = v_x - u_y\n",
    "            \n",
    "            return circulation\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in circulation analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def teleconnection_analysis(self, ds):\n",
    "        \"\"\"分析遥相关模态\"\"\"\n",
    "        self.logger.info(\"Analyzing teleconnection patterns...\")\n",
    "        teleconnections = {}\n",
    "        \n",
    "        try:\n",
    "            # 准备数据\n",
    "            data = ds['t2m'].stack(spatial=['latitude', 'longitude'])\n",
    "            \n",
    "            # 计算EOF\n",
    "            solver = Eof(data)\n",
    "            \n",
    "            # 获取前3个EOF模态\n",
    "            n_modes = 3\n",
    "            eofs = solver.eofs(neofs=n_modes)\n",
    "            pcs = solver.pcs(npcs=n_modes)\n",
    "            variance_fractions = solver.varianceFraction(neigs=n_modes)\n",
    "            \n",
    "            teleconnections = {\n",
    "                'eofs': eofs,\n",
    "                'pcs': pcs,\n",
    "                'variance_explained': variance_fractions\n",
    "            }\n",
    "            \n",
    "            return teleconnections\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in teleconnection analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def extreme_event_analysis(self, ds):\n",
    "        \"\"\"分析极端事件\"\"\"\n",
    "        self.logger.info(\"Analyzing extreme events...\")\n",
    "        extremes = {}\n",
    "        \n",
    "        try:\n",
    "            # 温度极值分析\n",
    "            if 't2m' in ds:\n",
    "                temp = ds['t2m']\n",
    "                q95 = temp.quantile(0.95, dim='valid_time')\n",
    "                q05 = temp.quantile(0.05, dim='valid_time')\n",
    "                \n",
    "                # 热浪定义：连续3天超过95百分位\n",
    "                hot_days = (temp > q95).astype(int)\n",
    "                hot_spells = self._find_persistent_events(hot_days, min_duration=3)\n",
    "                \n",
    "                # 寒潮定义：连续3天低于5百分位\n",
    "                cold_days = (temp < q05).astype(int)\n",
    "                cold_spells = self._find_persistent_events(cold_days, min_duration=3)\n",
    "                \n",
    "                extremes['temperature'] = {\n",
    "                    'hot_spells': hot_spells,\n",
    "                    'cold_spells': cold_spells\n",
    "                }\n",
    "            \n",
    "            # 降水极值分析\n",
    "            if 'tp' in ds:\n",
    "                precip = ds['tp']\n",
    "                p95 = precip.quantile(0.95, dim='valid_time')\n",
    "                \n",
    "                # 强降水事件\n",
    "                heavy_precip = (precip > p95).astype(int)\n",
    "                precip_events = self._find_persistent_events(heavy_precip, min_duration=1)\n",
    "                \n",
    "                extremes['precipitation'] = {\n",
    "                    'heavy_events': precip_events\n",
    "                }\n",
    "            \n",
    "            return extremes\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in extreme event analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _find_persistent_events(self, binary_series, min_duration):\n",
    "        \"\"\"辅助函数：识别持续性事件\"\"\"\n",
    "        events = []\n",
    "        current_spell = 0\n",
    "        \n",
    "        for t in range(len(binary_series.valid_time)):\n",
    "            if binary_series[t] == 1:\n",
    "                current_spell += 1\n",
    "            else:\n",
    "                if current_spell >= min_duration:\n",
    "                    events.append({\n",
    "                        'start': t - current_spell,\n",
    "                        'duration': current_spell\n",
    "                    })\n",
    "                current_spell = 0\n",
    "        \n",
    "        return events\n",
    "\n",
    "    def generate_report(self, stats, circulation, teleconnections, extremes):\n",
    "        \"\"\"生成分析报告\"\"\"\n",
    "        report_path = self.output_dir / 'climate_diagnostics_report.txt'\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"Climate Diagnostics Report\\n\")\n",
    "            f.write(\"========================\\n\\n\")\n",
    "            \n",
    "            # 基本统计\n",
    "            f.write(\"1. Basic Statistics\\n\")\n",
    "            f.write(\"----------------\\n\")\n",
    "            for var, var_stats in stats.items():\n",
    "                f.write(f\"\\nVariable: {var}\\n\")\n",
    "                f.write(f\"Mean: {float(var_stats['temporal_statistics']['mean'].mean()):.2f}\\n\")\n",
    "                f.write(f\"Std: {float(var_stats['temporal_statistics']['std'].mean()):.2f}\\n\")\n",
    "                f.write(\"Seasonal Variation:\\n\")\n",
    "                for season, value in var_stats['seasonal_means'].items():\n",
    "                    f.write(f\"  {season}: {float(value.mean()):.2f}\\n\")\n",
    "            \n",
    "            # 环流特征\n",
    "            f.write(\"\\n2. Circulation Characteristics\\n\")\n",
    "            f.write(\"---------------------------\\n\")\n",
    "            if circulation:\n",
    "                for metric, value in circulation.items():\n",
    "                    f.write(f\"\\n{metric}:\\n\")\n",
    "                    f.write(f\"Mean: {float(value.mean()):.2f}\\n\")\n",
    "                    f.write(f\"Std: {float(value.std()):.2f}\\n\")\n",
    "            \n",
    "            # 遥相关模态\n",
    "            f.write(\"\\n3. Teleconnection Patterns\\n\")\n",
    "            f.write(\"-------------------------\\n\")\n",
    "            if teleconnections:\n",
    "                for i, var in enumerate(teleconnections['variance_explained']):\n",
    "                    f.write(f\"EOF {i+1} explains {float(var)*100:.1f}% of variance\\n\")\n",
    "            \n",
    "            # 极端事件\n",
    "            f.write(\"\\n4. Extreme Events\\n\")\n",
    "            f.write(\"----------------\\n\")\n",
    "            if extremes:\n",
    "                if 'temperature' in extremes:\n",
    "                    f.write(\"\\nTemperature Extremes:\\n\")\n",
    "                    f.write(f\"Hot spells: {len(extremes['temperature']['hot_spells'])}\\n\")\n",
    "                    f.write(f\"Cold spells: {len(extremes['temperature']['cold_spells'])}\\n\")\n",
    "                \n",
    "                if 'precipitation' in extremes:\n",
    "                    f.write(\"\\nPrecipitation Extremes:\\n\")\n",
    "                    f.write(f\"Heavy events: {len(extremes['precipitation']['heavy_events'])}\\n\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 初始化分析器\n",
    "        analyzer = ClimateDiagnostics()\n",
    "        \n",
    "        # 加载数据\n",
    "        ds = xr.open_mfdataset(str(analyzer.data_dir / 'era5_*.nc'))\n",
    "        \n",
    "        # 执行分析\n",
    "        stats = analyzer.basic_statistics(ds)\n",
    "        circulation = analyzer.circulation_analysis(ds)\n",
    "        teleconnections = analyzer.teleconnection_analysis(ds)\n",
    "        extremes = analyzer.extreme_event_analysis(ds)\n",
    "        \n",
    "        # 生成报告\n",
    "        analyzer.generate_report(stats, circulation, teleconnections, extremes)\n",
    "        \n",
    "        print(\"Analysis completed successfully!\")\n",
    "        return {\n",
    "            'statistics': stats,\n",
    "            'circulation': circulation,\n",
    "            'teleconnections': teleconnections,\n",
    "            'extremes': extremes\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastSkillAnalyzer:\n",
    "    def __init__(self, data_dir='era5_data', output_dir='skill_assessment'):\n",
    "        \"\"\"初始化预测技巧评估器\"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.logger = self._setup_logger()\n",
    "        \n",
    "    def _setup_logger(self):\n",
    "        \"\"\"设置日志记录\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.output_dir / 'skill_assessment.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        return logging.getLogger('ForecastSkillAnalyzer')\n",
    "\n",
    "    def calculate_forecast_skill(self, ds, regions, lead_times=range(1, 36)):\n",
    "        \"\"\"计算不同提前期的预报技巧\"\"\"\n",
    "        self.logger.info(\"Calculating forecast skill metrics...\")\n",
    "        skill_metrics = {}\n",
    "        \n",
    "        try:\n",
    "            for region_name, region_coords in regions.items():\n",
    "                skill_metrics[region_name] = {}\n",
    "                \n",
    "                # 提取区域数据\n",
    "                region_data = ds.sel(**region_coords)\n",
    "                \n",
    "                for lead_time in lead_times:\n",
    "                    # 计算不同技巧评分\n",
    "                    acc = self._calculate_acc(region_data, lead_time)\n",
    "                    rmse = self._calculate_rmse(region_data, lead_time)\n",
    "                    crps = self._calculate_crps(region_data, lead_time)\n",
    "                    \n",
    "                    skill_metrics[region_name][lead_time] = {\n",
    "                        'ACC': acc,\n",
    "                        'RMSE': rmse,\n",
    "                        'CRPS': crps\n",
    "                    }\n",
    "            \n",
    "            return skill_metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating forecast skill: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_acc(self, ds, lead_time):\n",
    "        \"\"\"计算距平相关系数(Anomaly Correlation Coefficient)\"\"\"\n",
    "        try:\n",
    "            # 获取观测和预报数据\n",
    "            obs = ds['t2m'].values\n",
    "            fcst = np.roll(obs, -lead_time, axis=0)  # 模拟预报\n",
    "            \n",
    "            # 计算气候态\n",
    "            climatology = ds['t2m'].groupby('valid_time.dayofyear').mean()\n",
    "            \n",
    "            # 计算距平\n",
    "            obs_anom = obs - climatology\n",
    "            fcst_anom = fcst - climatology\n",
    "            \n",
    "            # 计算相关系数\n",
    "            acc = np.corrcoef(obs_anom.flatten(), fcst_anom.flatten())[0, 1]\n",
    "            \n",
    "            return acc\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating ACC: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_rmse(self, ds, lead_time):\n",
    "        \"\"\"计算均方根误差(Root Mean Square Error)\"\"\"\n",
    "        try:\n",
    "            obs = ds['t2m'].values\n",
    "            fcst = np.roll(obs, -lead_time, axis=0)  # 模拟预报\n",
    "            \n",
    "            # 计算RMSE\n",
    "            rmse = np.sqrt(np.mean((obs - fcst) ** 2))\n",
    "            \n",
    "            return rmse\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating RMSE: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_crps(self, ds, lead_time):\n",
    "        \"\"\"计算连续概率评分(Continuous Ranked Probability Score)\"\"\"\n",
    "        try:\n",
    "            obs = ds['t2m'].values\n",
    "            fcst = np.roll(obs, -lead_time, axis=0)  # 模拟预报\n",
    "            \n",
    "            # 生成预报集合\n",
    "            ensemble_size = 10\n",
    "            noise = np.random.normal(0, scale=0.1, size=(ensemble_size,) + fcst.shape)\n",
    "            ensemble_fcst = fcst[np.newaxis, :] + noise\n",
    "            \n",
    "            # 计算CRPS\n",
    "            crps = np.mean([np.abs(ensemble_fcst[i] - obs) for i in range(ensemble_size)])\n",
    "            \n",
    "            return crps\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating CRPS: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_predictability_sources(self, ds, regions):\n",
    "        \"\"\"分析预测技巧的来源\"\"\"\n",
    "        self.logger.info(\"Analyzing predictability sources...\")\n",
    "        predictability = {}\n",
    "        \n",
    "        try:\n",
    "            for region_name, region_coords in regions.items():\n",
    "                region_data = ds.sel(**region_coords)\n",
    "                \n",
    "                # 分析季节依赖性\n",
    "                seasonal_skill = self._analyze_seasonal_dependence(region_data)\n",
    "                \n",
    "                # 分析与遥相关模态的关系\n",
    "                teleconnection_impact = self._analyze_teleconnection_impact(region_data)\n",
    "                \n",
    "                # 分析初始条件的影响\n",
    "                initial_condition_impact = self._analyze_initial_conditions(region_data)\n",
    "                \n",
    "                predictability[region_name] = {\n",
    "                    'seasonal_dependence': seasonal_skill,\n",
    "                    'teleconnection_impact': teleconnection_impact,\n",
    "                    'initial_condition_impact': initial_condition_impact\n",
    "                }\n",
    "            \n",
    "            return predictability\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing predictability: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def generate_skill_report(self, skill_metrics, predictability):\n",
    "        \"\"\"生成预测技巧评估报告\"\"\"\n",
    "        report_path = self.output_dir / 'forecast_skill_report.txt'\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"Forecast Skill Assessment Report\\n\")\n",
    "            f.write(\"==============================\\n\\n\")\n",
    "            \n",
    "            # 技巧评分\n",
    "            f.write(\"1. Skill Metrics by Region\\n\")\n",
    "            f.write(\"------------------------\\n\")\n",
    "            for region, metrics in skill_metrics.items():\n",
    "                f.write(f\"\\n{region}:\\n\")\n",
    "                for lead_time, scores in metrics.items():\n",
    "                    f.write(f\"\\nLead Time {lead_time} days:\\n\")\n",
    "                    for metric, value in scores.items():\n",
    "                        f.write(f\"  {metric}: {value:.3f}\\n\")\n",
    "            \n",
    "            # 预测技巧来源\n",
    "            f.write(\"\\n2. Sources of Predictability\\n\")\n",
    "            f.write(\"--------------------------\\n\")\n",
    "            for region, sources in predictability.items():\n",
    "                f.write(f\"\\n{region}:\\n\")\n",
    "                \n",
    "                f.write(\"\\nSeasonal Dependence:\\n\")\n",
    "                for season, skill in sources['seasonal_dependence'].items():\n",
    "                    f.write(f\"  {season}: {skill:.3f}\\n\")\n",
    "                \n",
    "                f.write(\"\\nTeleconnection Impact:\\n\")\n",
    "                for mode, impact in sources['teleconnection_impact'].items():\n",
    "                    f.write(f\"  {mode}: {impact:.3f}\\n\")\n",
    "                \n",
    "                f.write(\"\\nInitial Condition Impact:\\n\")\n",
    "                for var, impact in sources['initial_condition_impact'].items():\n",
    "                    f.write(f\"  {var}: {impact:.3f}\\n\")\n",
    "\n",
    "        self.logger.info(f\"Skill assessment report generated: {report_path}\")\n",
    "        return report_path\n",
    "\n",
    "    def plot_skill_metrics(self, skill_metrics):\n",
    "        \"\"\"可视化预测技巧评估结果\"\"\"\n",
    "        self.logger.info(\"Generating skill visualization...\")\n",
    "        figures = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. 提前期-技巧图\n",
    "            fig1, ax1 = plt.subplots(figsize=(12, 8))\n",
    "            for region, metrics in skill_metrics.items():\n",
    "                lead_times = list(metrics.keys())\n",
    "                acc_values = [m['ACC'] for m in metrics.values()]\n",
    "                ax1.plot(lead_times, acc_values, marker='o', label=region)\n",
    "            \n",
    "            ax1.set_xlabel('Lead Time (days)')\n",
    "            ax1.set_ylabel('ACC')\n",
    "            ax1.set_title('Forecast Skill by Lead Time')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True)\n",
    "            \n",
    "            figures['lead_time_skill'] = fig1\n",
    "            \n",
    "            # 保存图片\n",
    "            for name, fig in figures.items():\n",
    "                fig.savefig(self.output_dir / f'skill_{name}.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "            \n",
    "            return figures\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error plotting skill metrics: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 初始化分析器\n",
    "        analyzer = ForecastSkillAnalyzer()\n",
    "        \n",
    "        # 加载数据\n",
    "        ds = xr.open_mfdataset(str(analyzer.data_dir / 'era5_*.nc'))\n",
    "        \n",
    "        # 定义分析区域\n",
    "        regions = {\n",
    "            'north_europe': {'latitude': slice(55, 65), 'longitude': slice(-10, 30)},\n",
    "            'central_europe': {'latitude': slice(45, 55), 'longitude': slice(-5, 20)},\n",
    "            'south_europe': {'latitude': slice(35, 45), 'longitude': slice(-10, 30)}\n",
    "        }\n",
    "        \n",
    "        # 计算预报技巧\n",
    "        skill_metrics = analyzer.calculate_forecast_skill(ds, regions)\n",
    "        \n",
    "        # 分析预测技巧来源\n",
    "        predictability = analyzer.analyze_predictability_sources(ds, regions)\n",
    "        \n",
    "        # 生成报告和可视化\n",
    "        report_path = analyzer.generate_skill_report(skill_metrics, predictability)\n",
    "        figures = analyzer.plot_skill_metrics(skill_metrics)\n",
    "        \n",
    "        print(\"Forecast skill assessment completed!\")\n",
    "        return {\n",
    "            'skill_metrics': skill_metrics,\n",
    "            'predictability': predictability,\n",
    "            'figures': figures\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
